{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "We are doing our analysis on [Spotify Multi-Genre Playlist Data](https://www.kaggle.com/siropo/spotify-multigenre-playlists-data).\n",
    "This dataset is a collection of song features taken from Spotify and separated into six broad genres of music. \n",
    "Our analysis aims to answer to solve two problems:\n",
    "1. How do you predict the genre of a song based on its features\n",
    "2. What song features are more influential to a particular genre. \n",
    "\n",
    "It is not a random sampling of songs on Spotify: each song was on a playlist made by the person who collected the dataset. \n",
    "However, there is still a wide variety of genres it will work for purposes of our analysis. \n",
    " \n",
    "The dataset has the following 22 columns:\n",
    "\n",
    "1. Artist Name\n",
    "2. Song Name\n",
    "3. Popularity: value from 1 to 100 that represents the song's popularity (magically determined by Spotify)\n",
    "4. Genres: a detailed list of the genres for each artist\n",
    "5. Playlist: the name of the playlist each song came from\n",
    "6. Danceability\n",
    "7. Energy\n",
    "8. Key\n",
    "9. Loudness\n",
    "9. Mode\n",
    "10. Speechiness\n",
    "11. Acousticness\n",
    "12. Instrumentalness\n",
    "13. Liveness\n",
    "14. Valence\n",
    "15. Tempo\n",
    "16. ID\n",
    "17. URI\n",
    "18. HRef\n",
    "19. Analysis_url\n",
    "19. Duration_Ms\n",
    "20. Time-Signature\n",
    "\n",
    "## Loading the dataset\n",
    "\n",
    "The dataset is broken into 6 files, with each file containing the songs from a single genre of music. \n",
    "Here, we load the files into memory and combine them into one dataset. \n",
    "We also drop the playlist, ID, URI, HRef, and Analysis_url columns because they are not relevant for our analysis. \n",
    "Since we will be combining all of the songs into a single dataset, we also have to add another column containing the genre of each song. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(music_genre):\n",
    "    # First, we read the genre dataset into memory\n",
    "    # Then we drop all of the columns we don't need\n",
    "    # and finally we add the genre column and return it \n",
    "    return pd.read_csv(f'{music_genre}_music_data.csv').drop(columns=['Playlist', 'id', 'uri', 'track_href', 'analysis_url']).assign(genre=music_genre)\n",
    "\n",
    "alternative = load_dataset('alternative')\n",
    "blues = load_dataset('blues')\n",
    "hiphop = load_dataset('hiphop')\n",
    "indie_alt = load_dataset('indie_alt')\n",
    "metal = load_dataset('metal')\n",
    "pop = load_dataset('pop')\n",
    "rock = load_dataset('rock')\n",
    "    \n",
    "dataset = pd.concat([alternative, blues, hiphop, indie_alt, metal, pop, rock])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "In the last logistic regression analysis, we determined variables are the least significant for identifying each genre. \n",
    "In this analysis, we will use forward variable selection to determine which variables are the most significant for distinguishing each genre. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "def make_genre_training_data(genre_name):# collect all of the songs that belong to the given genre (and ignore any columns that aren't song features)\n",
    "    X_same_genre = dataset[dataset['genre'] == genre_name].loc[:, 'danceability':'duration_ms']\n",
    "    # Collect the songs that don't belong to the given genre (collect only a random sample to ensure a balanced dataset)\n",
    "    X_different_genre = dataset[dataset['genre'] != genre_name].loc[:,'danceability':'duration_ms'].sample(n=len(X_same_genre))\n",
    "    \n",
    "    X_train = pd.concat([X_same_genre, X_different_genre], ignore_index=True)\n",
    "    \n",
    "    # for the Y data, we just need to make a dataframe of all 1s or all 0s with the same length as the X data\n",
    "    Y_same_genre = pd.DataFrame(index=range(len(X_same_genre)), columns=['genre']).assign(genre=1)\n",
    "    Y_different_genre = pd.DataFrame(index=range(len(X_same_genre)), columns=['genre']).assign(genre=0)\n",
    "\n",
    "    Y_train = pd.concat([Y_same_genre,Y_different_genre], ignore_index=True)\n",
    "    \n",
    "    return X_train, Y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function finds the most influential variable by building a separate logistic model for each feature and selecting the one with the lowest AIC score.\n",
    "By default, it just returns the name of the most influential variable.\n",
    "If you want to find the 2nd, 3rd, 4th, etc most influential variable, you can manually add variables to the logistic regression by using the fixed_vars parameter.\n",
    "For example, if I want to find the 2nd most influential variable for distinguishing metal music, and I know that the most influential variable is energy, then I would use: `find_best_variable('metal', ['energy'])`\n",
    "Also, you can change how verbose the function is. \n",
    "If the verbosity is set to a value greater than 0, it will also show the AIC score for each feature."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def find_best_variable(genre_name, default_cols=None, verbose=0):\n",
    "    if default_cols is None:\n",
    "\t    default_cols = []\n",
    "        \n",
    "    X_train_all_cols, Y_train = make_genre_training_data(genre_name)\n",
    "    \n",
    "    lowest_aic = math.inf\n",
    "    best_variable = ''\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(f'{genre_name}:')\n",
    "    \n",
    "    # loop through all columns (ignoring the ones that are already added to the logistic model)\n",
    "    for col in X_train_all_cols.drop(columns=default_cols):\n",
    "        # Creates list of the cols and the training data we'll be using to train the logistic model\n",
    "        training_cols = [col]\n",
    "        training_cols.extend(default_cols)\n",
    "        X_train = X_train_all_cols.loc[:,training_cols]\n",
    "\n",
    "        logistic_model = sm.Logit(Y_train, X_train).fit(disp=0)\n",
    "    \n",
    "        if logistic_model.aic < lowest_aic:\n",
    "            lowest_aic = logistic_model.aic\n",
    "            best_variable = col\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('  Variable:', col,'\\t| aic:', logistic_model.aic)\n",
    "        \n",
    "    return best_variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we find the most influential variable for distinguishing each genre, as determined by forward variable selection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uncomment this to see the AIC score for every metal logistic model\n",
    "# find_best_variable('metal', verbose=1)\n",
    "print('Best Variable for Alternative:', find_best_variable('alternative'))\n",
    "print('Best Variable for Blues:', find_best_variable('blues'))\n",
    "print('Best Variable for Hip Hop:', find_best_variable('hiphop'))\n",
    "print('Best Variable for Indie Alt:', find_best_variable('indie_alt'))\n",
    "print('Best Variable for Metal:', find_best_variable('metal'))\n",
    "print('Best Variable for Pop:', find_best_variable('pop'))\n",
    "print('Best Variable for Rock:', find_best_variable('rock'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results are somewhat surprising... [TODO: add analysis]\n",
    "\n",
    "In this section, we continue our forward variable selection to find the second most influential variable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_variable('metal', default_cols=['acousticness'], verbose=1)\n",
    "# TODO: add finish this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}